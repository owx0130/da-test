{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxRiaog5aOTr"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSat7UuUzicq",
        "outputId": "4ac8bd7a-6f5d-444f-edae-9c9097488b4c"
      },
      "outputs": [],
      "source": [
        "%pip install gower\n",
        "%pip install scikit-learn-extra\n",
        "%pip install pyxDamerauLevenshtein\n",
        "%pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IntGf1Kun5kV"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy.spatial import distance\n",
        "from pyxdameraulevenshtein import damerau_levenshtein_distance\n",
        "import gower\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwly42yGaVDu"
      },
      "source": [
        "# K-Means elbow method and K-Medoids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJEXxJJLozSr"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(iris.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWtxH4a0sEjX"
      },
      "source": [
        "Example of K-means elbow method ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf4bmomWpbQ8",
        "outputId": "039393ed-1257-44a9-bdc4-62f269517693"
      },
      "outputs": [],
      "source": [
        "# Calculate the within-cluster sum of squares across different cluster counts\n",
        "inertia = []\n",
        "for i in range (1, 11):\n",
        "  kmeans = KMeans(n_clusters=i, random_state=42, n_init='auto')\n",
        "  kmeans.fit(scaled_features)\n",
        "  inertia.append(kmeans.inertia_)\n",
        "#Plot the elbow graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 11), inertia, marker='o')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Within-cluster Sum of Square')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjRut1hmruq5"
      },
      "source": [
        "K-means example with iris dataset (https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4KTLHz4rcur",
        "outputId": "decda42e-85e7-4483-eb66-ca1e378e7342"
      },
      "outputs": [],
      "source": [
        "# Code source: GaÃ«l Varoquaux\n",
        "# Modified for documentation by Jaques Grobler\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Though the following import is not directly being used, it is required\n",
        "# for 3D projection to work with matplotlib < 3.2\n",
        "import mpl_toolkits.mplot3d  # noqa: F401\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "np.random.seed(5)\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "estimators = [\n",
        "    (\"k_means_iris_8\", KMeans(n_clusters=8)),\n",
        "    (\"k_means_iris_3\", KMeans(n_clusters=3)),\n",
        "    (\"k_means_iris_bad_init\", KMeans(n_clusters=3, n_init=1, init=\"random\")),\n",
        "]\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "titles = [\"8 clusters\", \"3 clusters\", \"3 clusters, bad initialization\"]\n",
        "for idx, ((name, est), title) in enumerate(zip(estimators, titles)):\n",
        "    ax = fig.add_subplot(2, 2, idx + 1, projection=\"3d\", elev=48, azim=134)\n",
        "    est.fit(X)\n",
        "    labels = est.labels_\n",
        "\n",
        "    ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=labels.astype(float), edgecolor=\"k\")\n",
        "\n",
        "    ax.xaxis.set_ticklabels([])\n",
        "    ax.yaxis.set_ticklabels([])\n",
        "    ax.zaxis.set_ticklabels([])\n",
        "    ax.set_xlabel(\"Petal width\")\n",
        "    ax.set_ylabel(\"Sepal length\")\n",
        "    ax.set_zlabel(\"Petal length\")\n",
        "    ax.set_title(title)\n",
        "\n",
        "# Plot the ground truth\n",
        "ax = fig.add_subplot(2, 2, 4, projection=\"3d\", elev=48, azim=134)\n",
        "\n",
        "for name, label in [(\"Setosa\", 0), (\"Versicolour\", 1), (\"Virginica\", 2)]:\n",
        "    ax.text3D(\n",
        "        X[y == label, 3].mean(),\n",
        "        X[y == label, 0].mean(),\n",
        "        X[y == label, 2].mean() + 2,\n",
        "        name,\n",
        "        horizontalalignment=\"center\",\n",
        "        bbox=dict(alpha=0.2, edgecolor=\"w\", facecolor=\"w\"),\n",
        "    )\n",
        "\n",
        "ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=y, edgecolor=\"k\")\n",
        "\n",
        "ax.xaxis.set_ticklabels([])\n",
        "ax.yaxis.set_ticklabels([])\n",
        "ax.zaxis.set_ticklabels([])\n",
        "ax.set_xlabel(\"Petal width\")\n",
        "ax.set_ylabel(\"Sepal length\")\n",
        "ax.set_zlabel(\"Petal length\")\n",
        "ax.set_title(\"Ground Truth\")\n",
        "\n",
        "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSQkgWvGsbX7"
      },
      "source": [
        "Another K-means example with iris dataset (https://www.geeksforgeeks.org/analyzing-decision-tree-and-k-means-clustering-using-iris-dataset/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgjYif_7sVpb",
        "outputId": "d7b03062-b565-4902-ad51-eced94e51614"
      },
      "outputs": [],
      "source": [
        "wcss = []\n",
        "\n",
        "for i in range(1, 11):\n",
        "\tkmeans = KMeans(n_clusters=i,\n",
        "\t\t\t\t\tinit='k-means++',\n",
        "\t\t\t\t\tmax_iter=300,\n",
        "\t\t\t\t\tn_init=10,\n",
        "\t\t\t\t\trandom_state=0)\n",
        "\tkmeans.fit(iris.data)\n",
        "\twcss.append(kmeans.inertia_)\n",
        "\n",
        "# from above array with help of elbow method\n",
        "#we can get no of cluster to provide.\n",
        "kmeans = KMeans(n_clusters=3,\n",
        "\t\t\t\tinit='k-means++',\n",
        "\t\t\t\tmax_iter=300,\n",
        "\t\t\t\tn_init=10,\n",
        "\t\t\t\trandom_state=0)\n",
        "y_kmeans = kmeans.fit_predict(iris.data)\n",
        "print(y_kmeans)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNWzi5XFtFfi",
        "outputId": "545ed876-160e-45fc-ca0b-b2154ad44c4b"
      },
      "outputs": [],
      "source": [
        "# Visualising the clusters\n",
        "coords = np.where(y_kmeans == 0)\n",
        "grid_0 = np.ix_(coords[0], [0])\n",
        "grid_1 = np.ix_(coords[0], [1])\n",
        "plt.scatter(iris.data[grid_0],\n",
        "            iris.data[grid_1],\n",
        "            s=100, c='purple',\n",
        "            label='Iris-setosa')\n",
        "\n",
        "coords = np.where(y_kmeans == 1)\n",
        "grid_0 = np.ix_(coords[0], [0])\n",
        "grid_1 = np.ix_(coords[0], [1])\n",
        "plt.scatter(iris.data[grid_0],\n",
        "            iris.data[grid_1],\n",
        "            s=100, c='orange',\n",
        "            label='Iris-versicolour')\n",
        "\n",
        "coords = np.where(y_kmeans == 2)\n",
        "grid_0 = np.ix_(coords[0], [0])\n",
        "grid_1 = np.ix_(coords[0], [1])\n",
        "plt.scatter(iris.data[grid_0],\n",
        "            iris.data[grid_1],\n",
        "            s=100, c='green',\n",
        "            label='Iris-virginica')\n",
        "print(iris.target)\n",
        "pd.crosstab(iris.target, y_kmeans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV9jENCT6fsU"
      },
      "source": [
        "Using Gower distance and KMedoids clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMjotHZdm-uk",
        "outputId": "142580ed-8235-4d2f-87c8-b4eaf72e0e41"
      },
      "outputs": [],
      "source": [
        "gower_dist = gower.gower_matrix(iris.data)\n",
        "clusters = (KMedoids(n_clusters=4,\n",
        "                           metric='precomputed',\n",
        "                           method='pam', init='build',\n",
        "                           random_state=0)\n",
        "            .fit(gower_dist)\n",
        "            .labels_)\n",
        "print(clusters)\n",
        "pd.crosstab(iris.target, clusters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtPlvsNyYxno"
      },
      "source": [
        "File reader code (backup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxXr-zFjYwv4"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# opening the file in read mode\n",
        "my_file = open(\"TRAIN.txt\", \"r\")\n",
        "\n",
        "# reading the file\n",
        "data = my_file.read()\n",
        "\n",
        "# replacing end splitting the text\n",
        "# when newline ('\\n') is seen.\n",
        "data_into_list = data.split(\"\\n\")\n",
        "my_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyKUD4lXX7is"
      },
      "source": [
        "# KNN classifier (classify into 3 classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNyLGgJmZ3Md"
      },
      "source": [
        "KNN classifier (training the classifier) (classify into 3 classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE3jFQztZ3Me",
        "outputId": "619e631b-d6ad-4d3b-b43d-7c6e0581ec28"
      },
      "outputs": [],
      "source": [
        "file = pd.read_csv(\"TRAIN.txt\", dtype=str, header=None, sep='|', na_filter=False)\n",
        "data = file.to_numpy()\n",
        "training_data = data[:, 0]\n",
        "training_labels = data[:, [1,2,3]]\n",
        "\n",
        "# calculate Damerau-Levenshtein distance between all samples\n",
        "levenshtein_dist = np.zeros((len(training_data), len(training_data)))\n",
        "for i in range(len(training_data)):\n",
        "  for j in range(len(training_data)):\n",
        "    levenshtein_dist[i, j] = damerau_levenshtein_distance(training_data[i].lower(), training_data[j].lower())\n",
        "\n",
        "print(levenshtein_dist)\n",
        "neigh = KNeighborsClassifier(n_neighbors=3, metric='precomputed', weights='distance')\n",
        "neigh.fit(levenshtein_dist, training_labels)\n",
        "\n",
        "# feed the classifier with training data\n",
        "prediction = neigh.predict(levenshtein_dist)\n",
        "print(classification_report(training_labels[:, 0], prediction[:, 0]))\n",
        "print(classification_report(training_labels[:, 1], prediction[:, 1]))\n",
        "print(classification_report(training_labels[:, 2], prediction[:, 2]))\n",
        "# print(confusion_matrix(training_labels, prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2c1cvMLZ3Me"
      },
      "source": [
        "KNN classifier (testing the classifier) (classify into 3 classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBd6yXjsZ3Me",
        "outputId": "865b5efb-6414-4b6c-99e6-2b91a0c77b22"
      },
      "outputs": [],
      "source": [
        "file = pd.read_csv(\"TEST.txt\", dtype=str, header=None, sep='|', na_filter=False)\n",
        "data = file.to_numpy()\n",
        "test_data = data[:, 0]\n",
        "test_labels = data[:, [1,2,3]]\n",
        "\n",
        "# calculate Damerau-Levenshtein distance between test samples and original training samples\n",
        "levenshtein_dist = np.zeros((len(test_data), len(training_data)))\n",
        "for i in range(len(test_data)):\n",
        "  for j in range(len(training_data)):\n",
        "    levenshtein_dist[i, j] = damerau_levenshtein_distance(test_data[i].lower(), training_data[j].lower())\n",
        "\n",
        "# feed the classifier with test data\n",
        "prediction = neigh.predict(levenshtein_dist)\n",
        "print(classification_report(test_labels[:, 0], prediction[:, 0]))\n",
        "print(classification_report(test_labels[:, 1], prediction[:, 1]))\n",
        "print(classification_report(test_labels[:, 2], prediction[:, 2]))\n",
        "# print(confusion_matrix(test_labels, prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbx5Eok-Z3Me"
      },
      "source": [
        "Printing out incorrect predictions (classify into 3 classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9owRwOKZ3Mf",
        "outputId": "029f7bee-9c67-4548-d781-c829d983e986"
      },
      "outputs": [],
      "source": [
        "class_1_labels = test_labels[:, 0]\n",
        "class_2_labels = test_labels[:, 1]\n",
        "class_3_labels = test_labels[:, 2]\n",
        "\n",
        "print(\"CLASS 1\")\n",
        "for i in range(len(prediction)):\n",
        "  if prediction[:, 0][i] != class_1_labels[i]:\n",
        "    print(prediction[:, 0][i], class_1_labels[i], test_data[i])\n",
        "\n",
        "print(\"CLASS 2\")\n",
        "for i in range(len(prediction)):\n",
        "  if prediction[:, 1][i] != class_2_labels[i]:\n",
        "    print(prediction[:, 1][i], class_2_labels[i], test_data[i])\n",
        "\n",
        "print(\"CLASS 3\")\n",
        "for i in range(len(prediction)):\n",
        "  if prediction[:, 2][i] != class_3_labels[i]:\n",
        "    print(prediction[:, 2][i], class_3_labels[i], test_data[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r39PQHuX-40"
      },
      "source": [
        "# KNN classifier (consider all classes as one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTtUhbQzZclX"
      },
      "source": [
        "KNN classifier (training the classifier) (consider all 3 classes together)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw04UoxnZclY",
        "outputId": "ae46ce0f-4205-4427-ff50-44165d094485"
      },
      "outputs": [],
      "source": [
        "file = pd.read_csv(\"TRAIN.txt\", dtype=str, header=None, sep='|', na_filter=False)\n",
        "data = file.to_numpy()\n",
        "training_data = data[:, 0]\n",
        "training_labels = data[:, 1]\n",
        "\n",
        "# calculate Damerau-Levenshtein distance between all samples\n",
        "levenshtein_dist = np.zeros((len(training_data), len(training_data)))\n",
        "for i in range(len(training_data)):\n",
        "  for j in range(len(training_data)):\n",
        "    levenshtein_dist[i, j] = damerau_levenshtein_distance(training_data[i].lower(), training_data[j].lower())\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3, metric='precomputed', weights='distance')\n",
        "neigh.fit(levenshtein_dist, training_labels)\n",
        "\n",
        "# feed the classifier with training data\n",
        "prediction = neigh.predict(levenshtein_dist)\n",
        "print(classification_report(training_labels, prediction))\n",
        "# print(confusion_matrix(training_labels, prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1M9bZd8ZclY"
      },
      "source": [
        "KNN classifier (testing the classifier) (consider all 3 classes together)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i63V091XZclZ",
        "outputId": "3f889079-6ba1-467e-b356-d02b41f6826a"
      },
      "outputs": [],
      "source": [
        "file = pd.read_csv(\"TEST.txt\", dtype=str, header=None, sep='|', na_filter=False)\n",
        "data = file.to_numpy()\n",
        "test_data = data[:, 0]\n",
        "test_labels = data[:, 1]\n",
        "\n",
        "# calculate Damerau-Levenshtein distance between test samples and original training samples\n",
        "levenshtein_dist = np.zeros((len(test_data), len(training_data)))\n",
        "for i in range(len(test_data)):\n",
        "  for j in range(len(training_data)):\n",
        "    levenshtein_dist[i, j] = damerau_levenshtein_distance(test_data[i].lower(), training_data[j].lower())\n",
        "\n",
        "# feed the classifier with test data\n",
        "prediction = neigh.predict(levenshtein_dist)\n",
        "print(classification_report(test_labels, prediction))\n",
        "# print(confusion_matrix(test_labels, prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls48PMPSZclZ"
      },
      "source": [
        "Printing out incorrect predictions (consider all 3 classes together)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OGVTFAoZclZ",
        "outputId": "c9720a2d-54d9-4b0e-fd8b-dbd4ebe6c152"
      },
      "outputs": [],
      "source": [
        "for i in range(len(prediction)):\n",
        "  if prediction[i] != test_labels[i]:\n",
        "    print(prediction[i], test_labels[i], test_data[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYaP2JZRZhVv"
      },
      "source": [
        "# K-Medoids clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMjQojz5cgvL"
      },
      "source": [
        "Read file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo0lOBBg4-E3",
        "outputId": "082490cd-d7ec-4953-8e4a-fe3bcbd35706"
      },
      "outputs": [],
      "source": [
        "file = pd.read_csv(\"vessel_arrival.csv\", dtype=str, na_filter=False)\n",
        "data = file.to_numpy()\n",
        "port_time_tide = data[:10000, [0,5,11]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYQmxZjtcizt"
      },
      "source": [
        "Perform clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hL-NZE4XZnH9"
      },
      "outputs": [],
      "source": [
        "gower_dist = gower.gower_matrix(data)\n",
        "print(gower_dist)\n",
        "clusters = (KMedoids(n_clusters=10,\n",
        "                           metric='precomputed',\n",
        "                           method='pam', init='build',\n",
        "                           random_state=0)\n",
        "            .fit(gower_dist)\n",
        "            .labels_)\n",
        "\n",
        "df = pd.DataFrame(data=clusters)\n",
        "df.to_csv(\"out.csv\", header=False, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JxRiaog5aOTr",
        "Hwly42yGaVDu",
        "IyKUD4lXX7is",
        "-r39PQHuX-40"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
