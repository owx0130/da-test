{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxRiaog5aOTr"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IntGf1Kun5kV"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy.spatial import distance\n",
        "from pyxdameraulevenshtein import damerau_levenshtein_distance\n",
        "from jaro import jaro_winkler_metric, jaro_metric\n",
        "import gower\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find optimal number of neighbours with K-Fold cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_folds = 4\n",
        "number_of_neighbours = 5\n",
        "\n",
        "file = pd.read_csv(\"DATA.txt\", dtype=str, header=None, sep='|', na_filter=False)\n",
        "data = file.to_numpy()\n",
        "kf = KFold(n_splits=number_of_folds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform K-Fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw04UoxnZclY",
        "outputId": "ae46ce0f-4205-4427-ff50-44165d094485"
      },
      "outputs": [],
      "source": [
        "for i, (train_index, test_index) in enumerate(kf.split(data)):\n",
        "  training_data = [data[j, 0] for j in train_index]\n",
        "  training_labels = [data[j, 1] for j in train_index]\n",
        "  test_data = [data[j, 0] for j in test_index]\n",
        "  test_labels = [data[j, 1] for j in test_index]\n",
        "\n",
        "  # calculate Damerau-Levenshtein distance between all training samples\n",
        "  levenshtein_dist = np.zeros((len(training_data), len(training_data)))\n",
        "  for i in range(len(training_data)):\n",
        "    for j in range(len(training_data)):\n",
        "      levenshtein_dist[i, j] = damerau_levenshtein_distance(training_data[i].lower(), training_data[j].lower())\n",
        "\n",
        "  # feed training data into model\n",
        "  neigh = KNeighborsClassifier(n_neighbors=number_of_neighbours, metric='precomputed', weights='distance')\n",
        "  neigh.fit(levenshtein_dist, training_labels)\n",
        "\n",
        "  # calculate Damerau-Levenshtein distance between test samples and original training samples\n",
        "  levenshtein_dist = np.zeros((len(test_data), len(training_data)))\n",
        "  for i in range(len(test_data)):\n",
        "    for j in range(len(training_data)):\n",
        "      levenshtein_dist[i, j] = damerau_levenshtein_distance(test_data[i].lower(), training_data[j].lower())\n",
        "  \n",
        "  # classification of test data\n",
        "  prediction = neigh.predict(levenshtein_dist)\n",
        "  print(classification_report(test_labels, prediction))\n",
        "  print(confusion_matrix(test_labels, prediction))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r39PQHuX-40"
      },
      "source": [
        "# KNN classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTtUhbQzZclX"
      },
      "source": [
        "Training the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = pd.read_csv(\"TRAIN.txt\", dtype=str, header=None, sep='|', na_filter=False)\n",
        "data = file.to_numpy()\n",
        "training_data = data[:, 0]\n",
        "training_labels = data[:, 1]\n",
        "\n",
        "# calculate Damerau-Levenshtein distance between all samples\n",
        "levenshtein_dist = np.zeros((len(training_data), len(training_data)))\n",
        "for i in range(len(training_data)):\n",
        "  for j in range(len(training_data)):\n",
        "      levenshtein_dist[i, j] = damerau_levenshtein_distance(training_data[i].lower(), training_data[j].lower())\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3, metric='precomputed', weights='distance')\n",
        "neigh.fit(levenshtein_dist, training_labels)\n",
        "\n",
        "# feed the classifier with training data\n",
        "prediction = neigh.predict(levenshtein_dist)\n",
        "print(classification_report(training_labels, prediction))\n",
        "# print(confusion_matrix(training_labels, prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1M9bZd8ZclY"
      },
      "source": [
        "Testing the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i63V091XZclZ",
        "outputId": "3f889079-6ba1-467e-b356-d02b41f6826a"
      },
      "outputs": [],
      "source": [
        "file = pd.read_csv(\"TEST.txt\", dtype=str, header=None, sep='|', na_filter=False)\n",
        "data = file.to_numpy()\n",
        "test_data = data[:, 0]\n",
        "test_labels = data[:, 1]\n",
        "\n",
        "# calculate Damerau-Levenshtein distance between test samples and original training samples\n",
        "levenshtein_dist = np.zeros((len(test_data), len(training_data)))\n",
        "for i in range(len(test_data)):\n",
        "  for j in range(len(training_data)):\n",
        "    levenshtein_dist[i, j] = damerau_levenshtein_distance(test_data[i].lower(), training_data[j].lower())\n",
        "\n",
        "# feed the classifier with test data\n",
        "prediction = neigh.predict(levenshtein_dist)\n",
        "print(classification_report(test_labels, prediction))\n",
        "print(confusion_matrix(test_labels, prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls48PMPSZclZ"
      },
      "source": [
        "Printing out incorrect predictions (consider all 3 classes together)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OGVTFAoZclZ",
        "outputId": "c9720a2d-54d9-4b0e-fd8b-dbd4ebe6c152"
      },
      "outputs": [],
      "source": [
        "wrong_predictions_idx = []\n",
        "for i in range(len(prediction)):\n",
        "  if prediction[i] != test_labels[i]:\n",
        "    wrong_predictions_idx.append(i)\n",
        "    print(prediction[i], test_labels[i], test_data[i])\n",
        "print(wrong_predictions_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYaP2JZRZhVv"
      },
      "source": [
        "# K-Medoids clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMjQojz5cgvL"
      },
      "source": [
        "Read file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo0lOBBg4-E3",
        "outputId": "082490cd-d7ec-4953-8e4a-fe3bcbd35706"
      },
      "outputs": [],
      "source": [
        "file = pd.read_csv(\"vessel_arrival.csv\", na_filter=False)\n",
        "data = file.to_numpy()\n",
        "port_time_tide = data[:, [0, 5, 13]]\n",
        "print(port_time_tide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYQmxZjtcizt"
      },
      "source": [
        "Perform clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hL-NZE4XZnH9"
      },
      "outputs": [],
      "source": [
        "input_data = port_time_tide\n",
        "number_of_clusters = 5\n",
        "\n",
        "gower_dist = gower.gower_matrix(input_data)\n",
        "\n",
        "clusters = (KMedoids(n_clusters=number_of_clusters,\n",
        "                           metric='precomputed',\n",
        "                           method='pam', init='build')\n",
        "            .fit(gower_dist)\n",
        "            .labels_)\n",
        "\n",
        "df = pd.DataFrame(data=clusters)\n",
        "df.to_csv(\"out.csv\", header=False, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JxRiaog5aOTr",
        "Hwly42yGaVDu",
        "IyKUD4lXX7is",
        "-r39PQHuX-40"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
